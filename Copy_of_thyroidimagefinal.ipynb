{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrHUgyG+NqvgPWtdg4wYgA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urmilapol/urmilapolprojects/blob/master/Copy_of_thyroidimagefinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZY6ahKxJnLS"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Flatten, Dense, Dropout, TimeDistributed, Conv2D, MaxPooling2D, LSTM, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "\n",
        "# --- 1. Data Loading ---\n",
        "\n",
        "# Assuming 'dataset.hdf5' and 'metadata.csv' are in the same directory\n",
        "HDF5_FILE = 'dataset.hdf5'\n",
        "METADATA_FILE = 'metadata.csv'\n",
        "\n",
        "def load_data(/content/sample_data/dataset.hdf5, /content/sample_data/metadata.csv):\n",
        "    \"\"\"\n",
        "    Loads cine-clip image data and metadata.\n",
        "    Note: Loading the entire HDF5 can be memory intensive.\n",
        "          Consider loading data in batches or on-the-fly during training.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with h5py.File(/content/sample_data/dataset.hdf5, 'r') as f:\n",
        "            # Assuming 'cine_clips' is the key for the image data\n",
        "            # The structure might be different, you'll need to inspect the HDF5 file\n",
        "            # Example: images = f['cine_clips'][:]\n",
        "            # For large datasets, you might iterate or use a custom data generator\n",
        "            print(f\"Keys in HDF5 file: {list(f.keys())}\")\n",
        "            # For demonstration, we'll assume a structure where 'images' and 'labels' are directly accessible\n",
        "            # You will likely need to map metadata to the image data\n",
        "            images = f['images'][:] # This is a placeholder, adapt based on actual HDF5 structure\n",
        "            # Check the shape of your images. It should be (num_clips, num_frames, height, width, channels)\n",
        "            print(f\"Shape of loaded images: {images.shape}\")\n",
        "\n",
        "        metadata_df = pd.read_csv(metadata_path)\n",
        "        print(f\"Shape of metadata: {metadata_df.shape}\")\n",
        "        return images, metadata_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        print(\"Please ensure 'dataset.hdf5' and 'metadata.csv' are in the correct path \"\n",
        "              \"and inspect the HDF5 file structure to access the correct keys.\")\n",
        "        return None, None\n",
        "\n",
        "# Example usage:\n",
        "# images, metadata_df = load_data(HDF5_FILE, METADATA_FILE)\n",
        "\n",
        "# For the purpose of a runnable example, let's create dummy data\n",
        "# In a real scenario, you'd load the actual data\n",
        "num_clips = 100\n",
        "frames_per_clip = 30\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "channels = 1 # Grayscale ultrasound images\n",
        "\n",
        "images = np.random.rand(num_clips, frames_per_clip, img_height, img_width, channels).astype(np.float32)\n",
        "metadata_df = pd.DataFrame({\n",
        "    'patient_id': [f'P{i}' for i in range(num_clips)],\n",
        "    'nodule_id': [f'N{i}' for i in range(num_clips)],\n",
        "    'age': np.random.randint(20, 80, num_clips),\n",
        "    'gender': np.random.choice(['M', 'F'], num_clips),\n",
        "    'lesion_size_mm': np.random.uniform(5, 50, num_clips),\n",
        "    'ti_rads': np.random.randint(2, 6, num_clips), # TI-RADS 2 to 5\n",
        "    'histopathological_diagnosis': np.random.choice(['benign', 'malignant'], num_clips, p=[0.8, 0.2])\n",
        "})\n",
        "print(\"Using dummy data for demonstration.\")\n",
        "print(f\"Dummy images shape: {images.shape}\")\n",
        "print(f\"Dummy metadata shape: {metadata_df.shape}\")\n",
        "\n",
        "\n",
        "# --- 2. Preprocessing ---\n",
        "\n",
        "def preprocess_metadata(df):\n",
        "    \"\"\"\n",
        "    Encodes categorical features and scales numerical features.\n",
        "    \"\"\"\n",
        "    # Encode 'gender'\n",
        "    le_gender = LabelEncoder()\n",
        "    df['gender_encoded'] = le_gender.fit_transform(df['gender'])\n",
        "\n",
        "    # Scale numerical features (age, lesion_size_mm, ti_rads)\n",
        "    scaler = StandardScaler()\n",
        "    df[['age_scaled', 'lesion_size_mm_scaled', 'ti_rads_scaled']] = \\\n",
        "        scaler.fit_transform(df[['age', 'lesion_size_mm', 'ti_rads']])\n",
        "\n",
        "    # Encode target variable\n",
        "    le_diagnosis = LabelEncoder()\n",
        "    df['diagnosis_encoded'] = le_diagnosis.fit_transform(df['histopathological_diagnosis'])\n",
        "    # Malignant will likely be 1, benign 0 (check mapping with le_diagnosis.classes_)\n",
        "    print(f\"Diagnosis classes: {le_diagnosis.classes_}\")\n",
        "\n",
        "    return df, le_diagnosis\n",
        "\n",
        "metadata_df, label_encoder = preprocess_metadata(metadata_df.copy()) # Use a copy to avoid modifying original df\n",
        "\n",
        "# Assuming you have a way to map images to their corresponding metadata entry\n",
        "# For this dummy data, we assume a 1:1 mapping by index\n",
        "image_data = images # This would be your actual loaded cine-clip data\n",
        "clinical_data = metadata_df[['age_scaled', 'gender_encoded', 'lesion_size_mm_scaled', 'ti_rads_scaled']].values\n",
        "labels = metadata_df['diagnosis_encoded'].values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_img_train, X_img_test, X_clin_train, X_clin_test, y_train, y_test = train_test_split(\n",
        "    image_data, clinical_data, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f\"X_img_train shape: {X_img_train.shape}\")\n",
        "print(f\"X_clin_train shape: {X_clin_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "\n",
        "\n",
        "# --- 3. Model Building (Deep Learning for Cine-clips + Clinical Data) ---\n",
        "\n",
        "def build_hybrid_model(input_shape_images, input_shape_clinical):\n",
        "    \"\"\"\n",
        "    Builds a hybrid deep learning model for disease prediction.\n",
        "    Combines a 3D CNN (for cine-clips) with a dense layer for clinical features.\n",
        "    \"\"\"\n",
        "    # Image Input Branch (3D CNN for cine-clips)\n",
        "    img_input = Input(shape=input_shape_images, name='image_input')\n",
        "    x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(img_input)\n",
        "    x = MaxPooling3D((2, 2, 2), padding='same')(x)\n",
        "    x = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling3D((2, 2, 2), padding='same')(x)\n",
        "    x = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling3D((2, 2, 2), padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    img_features = Dense(128, activation='relu')(x)\n",
        "    img_features = Dropout(0.5)(img_features)\n",
        "\n",
        "    # Clinical Data Input Branch\n",
        "    clinical_input = Input(shape=(input_shape_clinical,), name='clinical_input')\n",
        "    y = Dense(32, activation='relu')(clinical_input)\n",
        "    clinical_features = Dropout(0.2)(y)\n",
        "\n",
        "    # Concatenate features from both branches\n",
        "    combined_features = concatenate([img_features, clinical_features])\n",
        "\n",
        "    # Output Layer\n",
        "    z = Dense(64, activation='relu')(combined_features)\n",
        "    z = Dropout(0.3)(z)\n",
        "    output = Dense(1, activation='sigmoid', name='output_diagnosis')(z) # Sigmoid for binary classification\n",
        "\n",
        "    model = Model(inputs=[img_input, clinical_input], outputs=output)\n",
        "    return model\n",
        "\n",
        "# Define input shapes\n",
        "input_shape_images = (frames_per_clip, img_height, img_width, channels)\n",
        "input_shape_clinical = clinical_data.shape[1] # Number of clinical features\n",
        "\n",
        "model = build_hybrid_model(input_shape_images, input_shape_clinical)\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "# --- 4. Training ---\n",
        "\n",
        "# You might need to adjust batch_size and epochs based on your hardware and dataset size\n",
        "batch_size = 8 # Smaller batch size for cine-clips due to memory\n",
        "epochs = 10\n",
        "\n",
        "# Create TensorFlow datasets for better performance and memory management\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    ({\"image_input\": X_img_train, \"clinical_input\": X_clin_train}, y_train)\n",
        ").shuffle(buffer_size=1024).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    ({\"image_input\": X_img_test, \"clinical_input\": X_clin_test}, y_test)\n",
        ").batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_dataset\n",
        ")\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "\n",
        "# --- 5. Evaluation ---\n",
        "\n",
        "print(\"\\nEvaluating model performance on test set...\")\n",
        "loss, accuracy, auc = model.evaluate(test_dataset)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test AUC: {auc:.4f}\")\n",
        "\n",
        "# --- 6. Prediction Example ---\n",
        "\n",
        "def predict_new_patient(model, new_image_clip, new_clinical_data, label_encoder):\n",
        "    \"\"\"\n",
        "    Makes a prediction for a single new patient.\n",
        "    \"\"\"\n",
        "    # Ensure inputs are in the correct batch format for the model\n",
        "    new_image_clip_batch = np.expand_dims(new_image_clip, axis=0)\n",
        "    new_clinical_data_batch = np.expand_dims(new_clinical_data, axis=0)\n",
        "\n",
        "    prediction_proba = model.predict([new_image_clip_batch, new_clinical_data_batch])[0][0]\n",
        "    predicted_class_idx = (prediction_proba > 0.5).astype(int)\n",
        "    predicted_diagnosis = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
        "\n",
        "    return predicted_diagnosis, prediction_proba\n",
        "\n",
        "# Example new data (replace with actual new patient data)\n",
        "# Remember to preprocess new clinical data using the same scalers/encoders\n",
        "# used during training!\n",
        "sample_index = np.random.randint(0, len(X_img_test))\n",
        "sample_image_clip = X_img_test[sample_index]\n",
        "sample_clinical_data = X_clin_test[sample_index]\n",
        "true_diagnosis = label_encoder.inverse_transform([y_test[sample_index]])[0]\n",
        "\n",
        "predicted_diagnosis, prediction_proba = predict_new_patient(\n",
        "    model, sample_image_clip, sample_clinical_data, label_encoder\n",
        ")\n",
        "\n",
        "print(f\"\\n--- Prediction for a Sample Patient ---\")\n",
        "print(f\"True Diagnosis: {true_diagnosis}\")\n",
        "print(f\"Predicted Diagnosis: {predicted_diagnosis}\")\n",
        "print(f\"Prediction Probability (Malignant): {prediction_proba:.4f}\")\n",
        "\n",
        "# You can also save your trained model\n",
        "# model.save('thyroid_nodule_detection_model.h5')\n",
        "# print(\"Model saved to thyroid_nodule_detection_model.h5\")\n"
      ]
    }
  ]
}