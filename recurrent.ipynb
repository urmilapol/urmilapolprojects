{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recurrent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urmilapol/urmilapolprojects/blob/master/recurrent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Description:\n",
        "An implementation of the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original. For more reading see [here](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "## Results\n",
        "* Wiring up a basic sequence-to-sequence computation graph\n",
        "* Implementing a GRU cell.\n",
        "\n",
        "\n",
        "An example of my final samples are shown below after 150 passes through the Lord of the Rings text dataset.\n",
        "\n",
        "<code>\n",
        "eide and the cece the eviled understade and Shire. \n",
        "Them. And the rider his allove. \n",
        "It he hape\n",
        " eer was need to of more blown to still new rithed to have collong to not the our to the \n",
        "mucker abou\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Data loading and high level training\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7bdZWxvJrsx",
        "outputId": "e413653e-f600-427b-a8ba-7744437b0dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-07 10:41:19--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 3.221.126.233, 18.214.211.171, 52.7.218.200, ...\n",
            "Connecting to piazza.com (piazza.com)|3.221.126.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2022-01-07 10:41:19--  https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving cdn-uploads.piazza.com (cdn-uploads.piazza.com)... 52.222.138.21, 52.222.138.65, 52.222.138.20, ...\n",
            "Connecting to cdn-uploads.piazza.com (cdn-uploads.piazza.com)|52.222.138.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "./text_files.tar.gz 100%[===================>]   1.46M  2.68MB/s    in 0.5s    \n",
            "\n",
            "2022-01-07 10:41:20 (2.68 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 11.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "file_len = 2579888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxBeKeNjJ0NQ",
        "outputId": "659f2730-ec5e-46ad-ddbf-f821931299e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n",
        "  \n",
        "print(random_chunk())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " falling to the ground, rising, and falling again. And all \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the while he hissed but spoke no words. \n",
            "\n",
            "The fires below awoke in anger, the red light blazed, and all the \n",
            "cavern was filled with a gre\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On0_WitWJ99e",
        "outputId": "2b00c496-977b-42cd-8db8-11316526b206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return Variable(tensor)\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Creating a GRU cell \n",
        "\n",
        "---\n",
        "\n",
        "The cell I used previously was a pre-defined Pytorch layer. I will now write a  GRU class using the same parameters as the built-in Pytorch class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavAv50ZKQ-F"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(GRU, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "    \n",
        "    self.W_ir = nn.Linear(input_size, hidden_size)\n",
        "    self.W_hr = nn.Linear(hidden_size, hidden_size)\n",
        "    \n",
        "    self.W_iz = nn.Linear(input_size, hidden_size)\n",
        "    self.W_hz = nn.Linear(hidden_size, hidden_size)\n",
        "    \n",
        "    self.W_in = nn.Linear(input_size, hidden_size)\n",
        "    self.W_hn = nn.Linear(hidden_size, hidden_size)\n",
        "      \n",
        "  def forward(self, inputs, hidden):\n",
        "    # hidden : (n_layers, batch, hidden_size)\n",
        "    \n",
        "    # Each layer does the following:\n",
        "    # r_t = sigmoid(W_ir*x_t + b_ir + W_hr*h_(t-1) + b_hr)\n",
        "    # z_t = sigmoid(W_iz*x_t + b_iz + W_hz*h_(t-1) + b_hz)\n",
        "    # n_t = tanh(W_in*x_t + b_in + r_t**(W_hn*h_(t-1) + b_hn))\n",
        "    # h_(t) = (1 - z_t)**n_t + z_t**h_(t-1)\n",
        "    # Where ** is hadamard product (not matrix multiplication, but elementwise multiplication)\n",
        "    r_t = self.sigmoid(self.W_ir(inputs) + self.W_hr(hidden))\n",
        "    z_t = self.sigmoid(self.W_iz(inputs) + self.W_hz(hidden))\n",
        "    n_t = self.tanh(self.W_in(inputs) + r_t * (self.W_hn(hidden)))\n",
        "    hiddens = (1 - z_t) * n_t + z_t * hidden\n",
        "    \n",
        "    return n_t, hiddens"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Building a sequence to sequence model\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6tNdEnzWj5F"
      },
      "source": [
        "#linear layer takes hidden size and shrinks it to vocab size\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size # num characters\n",
        "    self.hidden_size = hidden_size # 200\n",
        "    self.output_size = output_size # num characters\n",
        "    self.n_layers = n_layers # 3\n",
        "  \n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = GRU(hidden_size, hidden_size, n_layers)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input_char, hidden):\n",
        "    output = self.embedding(input_char).view(1, 1, -1)\n",
        "    \n",
        "    output = F.relu(output)\n",
        "    \n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    \n",
        "    output = self.out(output[0])\n",
        "    \n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhXghEPKD-5"
      },
      "source": [
        "def random_training_set():    \n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALC3Pf8Kbsi"
      },
      "source": [
        "import itertools\n",
        "\n",
        "def train(decoder, decoder_optimizer, criterion, inp, target):\n",
        "  ## initialize hidden layers, set up gradient and loss \n",
        "  decoder_optimizer.zero_grad()\n",
        "  hidden = decoder.init_hidden()\n",
        "  loss = 0\n",
        "  \n",
        "  for x, y in zip(inp, target):\n",
        "    y_hat, hidden = decoder(x, hidden)\n",
        "    \n",
        "    loss += criterion(y_hat, y.unsqueeze(0))\n",
        "   \n",
        "  loss.backward()\n",
        "  decoder_optimizer.step()\n",
        "  return loss.item() / target.shape[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Sampling text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "This method takes as input a decoder and creates a string of the given length.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-bp-OZ1KjNh"
      },
      "source": [
        "def evaluate(decoder, prime_str='A', predict_len=100, temperature=0.8):\n",
        "  ## initialize hidden variable, initialize other useful variables \n",
        "    # your code here\n",
        "  ## /\n",
        "  prime_str = char_tensor(prime_str)\n",
        "  hidden = decoder.init_hidden()\n",
        "  output_str = \"\"\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    while len(output_str) < predict_len:\n",
        "      for char in prime_str:\n",
        "        prediction, hidden = decoder(char, hidden)\n",
        "        \n",
        "        prediction = torch.exp(prediction / temperature)\n",
        "        \n",
        "        sample_index = torch.multinomial(prediction, 1)\n",
        "        \n",
        "        output_str += all_characters[sample_index]\n",
        "      \n",
        "      prime_str = sample_index\n",
        "  \n",
        "  return output_str"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Running it and generating some text!\n",
        "\n",
        "---\n",
        "Now time to run the model. This will train the model outputting sample strings along the way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKfozqw-6eqb",
        "outputId": "a9346c33-4bdc-4f0e-e63a-6ff534ffa219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "import gc\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "\n",
        "def print_strings(strings):\n",
        "  for i in range(len(strings)):\n",
        "    print(\"\\n\\t--------- output string \", i+1, \" -----------\\n\", strings[i])\n",
        "\n",
        "\n",
        "def run():\n",
        "  try:\n",
        "    gc.collect()\n",
        "    \n",
        "    n_epochs = 2000\n",
        "    print_every = 130\n",
        "    plot_every = 200\n",
        "    hidden_size = 200\n",
        "    n_layers = 1\n",
        "    lr = 0.001\n",
        "\n",
        "    decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    start = time.time()\n",
        "    all_losses = []\n",
        "    output_strings = []\n",
        "    loss_avg = 0\n",
        "\n",
        "    loop = tqdm(total=n_epochs, position=0, leave=False)\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "      loss_ = train(decoder, decoder_optimizer, criterion, *random_training_set())       \n",
        "      loss_avg += loss_\n",
        "\n",
        "      if epoch % print_every == 0:\n",
        "          output_strings.append(evaluate(decoder, 'Wh', 100))\n",
        "\n",
        "      if epoch % plot_every == 0:\n",
        "          all_losses.append(loss_avg / plot_every)\n",
        "          loss_avg = 0\n",
        "\n",
        "      loop.set_description('loss:{:.4f}'.format(loss_))\n",
        "      loop.update(1)\n",
        "\n",
        "    return output_strings, all_losses, decoder\n",
        "\n",
        "  except:\n",
        "      __ITB__()\n",
        "\n",
        "output_strings, all_losses, decoder = run()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2EFfOvGb2No",
        "outputId": "96ca8c2e-a032-4c2a-8ce9-306e2bf820ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print_strings(output_strings)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t--------- output string  1  -----------\n",
            " eei wane and athe fats Nheerelld to win! ghes 'of dong \n",
            "'oft bbe hit fod the lo+ Dast no Af of theg \n",
            "\n",
            "\t--------- output string  2  -----------\n",
            "  er the lind pars the he borte the and pote sor we done and upland tith aing the the the soner \n",
            "the \n",
            "\n",
            "\t--------- output string  3  -----------\n",
            " ee no, his. Them deen it ons \n",
            "for of ros sill outs wito se the sood of tine and swith not enico shin\n",
            "\n",
            "\t--------- output string  4  -----------\n",
            " hild tur there with wast, of the Sould trome hor hig the horigh byer uilod alit be ill their wit the\n",
            "\n",
            "\t--------- output string  5  -----------\n",
            " eing, and his were manking in the going wereh. \n",
            "\n",
            "'We \n",
            "then cralk whe was the Enfing andy grounn free\n",
            "\n",
            "\t--------- output string  6  -----------\n",
            " eat ba-bethaally out on \n",
            "the meght they \n",
            "\n",
            "Frodo light the Harst and shoutaled cag's on the singed th\n",
            "\n",
            "\t--------- output string  7  -----------\n",
            " hed and greatt!' \n",
            "\n",
            "That the now tho6 the swiated to lowerss, thated. Hach some of the Nort? There th\n",
            "\n",
            "\t--------- output string  8  -----------\n",
            " iere himsell just for a greal they were to bropning of that wold the was breet hour ortrilangain. Th\n",
            "\n",
            "\t--------- output string  9  -----------\n",
            " een the woursewill \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "'The Hound pintly into a that was abust and glese sill poth. 'Whin't Frodo\n",
            "\n",
            "\t--------- output string  10  -----------\n",
            " ees he sad bated to bed the cone in evany dreaming. \n",
            "Merrying to \n",
            "the sluffle only a nees.' \n",
            "\n",
            "'I wit\n",
            "\n",
            "\t--------- output string  11  -----------\n",
            " ee one, \n",
            "\n",
            "But light and fame to petterf. 'We is ie lift in sterded and greep hearts hall. In dream \n",
            "\n",
            "\n",
            "\t--------- output string  12  -----------\n",
            " eere cursele not of the meried ferver, but I troming there doonsall there the lagstares or \n",
            "compinfi\n",
            "\n",
            "\t--------- output string  13  -----------\n",
            " iere of the wist know, and the lond of the Dropped. Yet know, \n",
            "wind. \n",
            "\n",
            "'No-that ever by a kind. He g\n",
            "\n",
            "\t--------- output string  14  -----------\n",
            " ees was it hus of \n",
            "come deward. And yet was you many are their was do did better ware not crome the \n",
            "\n",
            "\t--------- output string  15  -----------\n",
            " e the kind this had great day strear, in the malmer up to knows in it with the starang with it men t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0so6aKJ5L8",
        "outputId": "f8332c61-2fde-42a1-b76f-38feab203156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(decoder, start_strings[start], 200), '\\n')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " lo\n",
            "aiught to the could man like the Land you, the sone a read \n",
            "whide the slow, munt under fer the plans, I do to jomer it thought his had should way back and \n",
            "this life had \n",
            "could sile leaped the \n",
            "black  \n",
            "\n",
            " G\n",
            "sandalf \n",
            "place was seaken on the morn's and long littless and \n",
            "the tolmil had such to shid, on his is a fell fell. He was into Midor? For he Sam hall reaty stwards the passess and Shorget up to that r \n",
            "\n",
            " I \n",
            "s cowly, and he and falitil wind the blace unour hobe, was to the \n",
            "water stallly into hard \n",
            "fars my reet were the \n",
            "right, and the hobbits hosened to \n",
            "the inder \n",
            "the mace \n",
            "still, and such a recom the E \n",
            "\n",
            " ra\n",
            "tesh abod is of and \n",
            "said, at in the tearn the slow it arm the homper had least the sen upon, you soud, shadol he many. But the Hound of the surmer and the clowed, the sheld by a blawn, the may and be \n",
            "\n",
            " he\n",
            "ci peary upon the leves, and shot ex, Touthered they and all may the clumped than the long with went, and was and palled to the Sarown indee, steary \n",
            "pind. \n",
            "\n",
            "'I scold with \n",
            "the prouse: and a dring hom \n",
            "\n",
            " ra\n",
            "wins of \n",
            "the \n",
            "cook. \n",
            "\n",
            "'Ban's the romir was ever and the \n",
            "marb? \n",
            "'Gimlig old about lalt whing the speanly North take \n",
            "he sall the horses as it was be sword of the rishal find the back as he canyed \n",
            "and \n",
            "\n",
            " Th\n",
            "yhe \n",
            "say. \n",
            "\n",
            "He side, by the oldes; and thirke about then he wath the readed, and he sunts \n",
            "ever the Mifunce, \"should, but the mothes to the bastled this bang wind! \n",
            "\n",
            "'A do that came that you in neath  \n",
            "\n",
            " Th\n",
            "nlat still my able rolled and feam. \n",
            "\n",
            "The Nort he stapes lest mess \n",
            "the root, nown some to they netter stoot strough that stills, and are may the cast there. \n",
            "\n",
            "' \n",
            "\n",
            "'We what need by \n",
            "midden the lang si \n",
            "\n",
            " wh\n",
            "hhen the came to should that its the borst holes and the \n",
            "steady us \n",
            "\n",
            "\n",
            "goved be wind \n",
            "the hight show stead, so horm \n",
            "\n",
            "yet \n",
            "at \n",
            "the holes the had it he say pass good the batter the som one the wards by \n",
            "\n",
            " wh\n",
            "seite was and bread \n",
            "of the \n",
            "cime; aboug the vallath, and \n",
            "the Sames stang, by the Sall of roin, and mun than that he \n",
            "any \n",
            "leath the sward towed and many again. The milmed not \n",
            "gver on him. It we bre \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Generating output on a different dataset\n",
        "\n",
        "---\n",
        "I will now generate output from a Shakespeare dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OZUHyNHJKUu",
        "outputId": "b8f5119a-3638-47dc-d093-3e05ee865d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "file = unidecode.unidecode(open(path_to_file).read())\n",
        "file_len = len(file)\n",
        "all_characters = sorted(set(file))\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "output_strings2, all_losses2, _ = run()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv0lSqxjQuqV",
        "outputId": "165c2789-0585-482c-fe42-352dc31dd3be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print_strings(output_strings2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t--------- output string  1  -----------\n",
            " hord oigenst wea chel con\n",
            "\n",
            "ITDAiW boMuracre ay thesthell.\n",
            "\n",
            "I:\n",
            "WrRDGNNOERIO:\n",
            "Mind?\n",
            "Mow hate the thitu\n",
            "\n",
            "\t--------- output string  2  -----------\n",
            " hat thay he wentiss ther aneressbe,\n",
            "Dere derd beithed,\n",
            "Cat and apreentere ow surd tham the Wo cablef\n",
            "\n",
            "\t--------- output string  3  -----------\n",
            "  or denker.\n",
            "is me it 'leek ar cpon, weaciner, of you?\n",
            "I has on the this in ofes\n",
            "\n",
            "COUCIUCE RINIENT:\n",
            "A\n",
            "\n",
            "\t--------- output string  4  -----------\n",
            " eer, hairs, door lighall,\n",
            "Whee leens to thy Whath ste diving.\n",
            "\n",
            "AOUS:\n",
            "Peer are it siess the with dice\n",
            "\n",
            "\t--------- output string  5  -----------\n",
            "  ere welpight with will so plotst cand\n",
            "Benot no, well them bivatice caman struth that to me simme?\n",
            "\n",
            "\n",
            "\n",
            "\t--------- output string  6  -----------\n",
            " e the with lay!\n",
            "\n",
            "KIOND MINUS:\n",
            "Now chrevery neseld the oforest the monss\n",
            "Comread, may amelam the to h\n",
            "\n",
            "\t--------- output string  7  -----------\n",
            " he, and, it sight,\n",
            "Condenterfed so that lards will for chall the pracem,\n",
            "And her shou my not thit re\n",
            "\n",
            "\t--------- output string  8  -----------\n",
            " eat dast onter the dear to the,\n",
            "I so sircter, my she's the soos it sume.\n",
            "\n",
            "DUKE LHARD IIY:\n",
            "That list \n",
            "\n",
            "\t--------- output string  9  -----------\n",
            " hat.\n",
            "\n",
            "SARDTIO:\n",
            "Thus.\n",
            "\n",
            "TROKES:\n",
            "So cance the and me this stainess to that the words for aster that wea\n",
            "\n",
            "\t--------- output string  10  -----------\n",
            " hat the evin them such slown,\n",
            "As own enconter to goor have our her fathers;\n",
            "Have lakes the cromming \n",
            "\n",
            "\t--------- output string  11  -----------\n",
            " eou thee the ploop? Whendious ser\n",
            "O, my lord, bad, then are counderth crost,\n",
            "Poyslaf, bear the kingr\n",
            "\n",
            "\t--------- output string  12  -----------\n",
            " eere have to sorr.\n",
            "\n",
            "HENRING RICHLONTES:\n",
            "Gow the king not, and Prown,\n",
            "Gown, as wall-bear sees yeir fa\n",
            "\n",
            "\t--------- output string  13  -----------\n",
            " hich and my fore long?\n",
            "\n",
            "BAPULUCESTER:\n",
            "Bithou should soone the prorest Show we by the crood with?\n",
            "\n",
            "AU\n",
            "\n",
            "\t--------- output string  14  -----------\n",
            " eat were spasher;\n",
            "And his liantly gome, and ever fallows,\n",
            "Brather beself you senting are still\n",
            "Strin\n",
            "\n",
            "\t--------- output string  15  -----------\n",
            " ee show thee you should for may sode.\n",
            "\n",
            "CUTUCHIO:\n",
            "There is not the rough have nope oo done\n",
            "To I befor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ41Z_FsXFF5"
      },
      "source": [
        "**Performance evaluation**\n",
        "\n",
        "I'd say my model did pretty well. It was able to change styles of writing depending on the dataset and actually outputted english words."
      ]
    }
  ]
}