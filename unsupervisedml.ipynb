{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "file_extension": ".py",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "name": "unsupervisedml.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urmilapol/urmilapolprojects/blob/master/unsupervisedml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised Learning Tutorial"
      ],
      "metadata": {
        "_uuid": "da676610bd7728ed4e1d30c0862928052c0bef30",
        "_cell_guid": "3f8e061b-cb3f-48a9-a60e-51696b1a2471",
        "id": "ZdtHuYGO-f38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "import sklearn.metrics as sm\n",
        " \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        "# Only needed if you want to display your plots inline if using Notebook\n",
        "# change inline to auto if you have Spyder installed\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "_uuid": "e880de45c4586c2352050a2f92e8276da5ef5d0d",
        "_cell_guid": "866df12f-fb39-4454-ab8f-b3a81cea1152",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "cjwRfoKm-f3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import some data to play with\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "_uuid": "e638a8eaa4aff63fd508d99fa1d32abdaf23b1d4",
        "_cell_guid": "177bf3e0-1c48-4691-b097-eaf2ac7aac8f",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "MRX8Hbe8-f4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mapping target labels to target names"
      ],
      "metadata": {
        "_uuid": "dc1806797f77fc814681444013540efe76adfdb1",
        "_cell_guid": "ffa67cc8-cd46-4f2f-9da1-00b88d29dbe3",
        "id": "1g13Gkte-f4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "species_dict = dict(zip(range(0, len(iris.target_names)), iris.target_names))\n",
        "\n",
        "iris_species = list((map(lambda x : species_dict[x], iris.target)))"
      ],
      "metadata": {
        "_uuid": "ae148370d10688179638737ee445adc52582cca6",
        "_cell_guid": "413b7b46-2d83-4562-a8bd-63f16b77919f",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "opf1-67V-f4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore the data"
      ],
      "metadata": {
        "_uuid": "3696c1761f779e496603739f76ef7d3c620cbc25",
        "_cell_guid": "ebe0dae0-b064-4f17-a6ae-cd00dc5f72a9",
        "id": "yhZhEuLC-f4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris.data"
      ],
      "metadata": {
        "_uuid": "500ae063ed340d4ec2d3d19e6153e0853123149a",
        "_cell_guid": "15519fc0-9360-4c37-9edc-8ee6baf885f2",
        "id": "kNEUKztX-f4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.feature_names"
      ],
      "metadata": {
        "_uuid": "c790e06cdc6487f996518aa280b1e426e261d92f",
        "_cell_guid": "9dffb355-924d-4168-b2ac-e717d2681a1e",
        "id": "SXETL9n9-f4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](http://5047-presscdn.pagely.netdna-cdn.com/wp-content/uploads/2015/04/iris_petal_sepal.png)"
      ],
      "metadata": {
        "_uuid": "f0ded7ad87b5de138fd72d2251f1e91cfa923b89",
        "_cell_guid": "a684d23c-753c-48f9-a31f-bc0fc4c2d907",
        "id": "2n6l8cgQ-f4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target"
      ],
      "metadata": {
        "_uuid": "b313c26889ceacd643146fee8a6ad8fe82a8b646",
        "_cell_guid": "aeea99fe-c086-4611-aa27-1c1477285ed6",
        "id": "a6c34eXK-f4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target_names"
      ],
      "metadata": {
        "_uuid": "0b8e6643b204b912223b4ae4ba037c5ae17202b2",
        "_cell_guid": "28175141-7698-4f26-9082-ef78b9a90da9",
        "id": "-rp14x8S-f4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i1.wp.com/dataaspirant.com/wp-content/uploads/2017/01/irises.png?resize=600%2C181)"
      ],
      "metadata": {
        "_uuid": "2d33997c8627cfa4b7f295ce63bb929c90a5c083",
        "_cell_guid": "0988783c-3416-46f6-b582-dd67e7b7374b",
        "id": "F5-dwXlK-f4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the inputs as a Pandas Dataframe and set the column names\n",
        "x = pd.DataFrame(iris.data, columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width'])\n",
        " \n",
        "y = pd.DataFrame(iris.target, columns = ['Targets'])"
      ],
      "metadata": {
        "_uuid": "075823bb5645261e784dfe2faffb622388e01022",
        "_cell_guid": "75657fd0-3bb3-4c2e-9a4e-ace16f0ca43c",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "mEIVNImG-f4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the data"
      ],
      "metadata": {
        "_uuid": "c2bf4b72feb415a4a6ffaed1a914de60557551fa",
        "_cell_guid": "9a773f03-ddb4-4e63-99b3-1767555be376",
        "id": "yTamL0GN-f4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How many clusters?"
      ],
      "metadata": {
        "_uuid": "8eeb768dd33867317af9e3c6cb29a3a4f4128d72",
        "_cell_guid": "5d72672e-442a-46bd-a158-a22a3a41ad16",
        "id": "KHJkVbxV-f4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are given an array points of size 150x4. As seen above, our features are sepal length (cm), sepal width (cm), petal length (cm), petal width (cm).\n",
        "\n",
        "matplotlib.pyplot has already been imported as plt.\n",
        "\n",
        "Make a scatter plot by passing x.Sepal_Length and x.Sepal_Width to the plt.scatter() function.\n",
        "Make a scatter plot by passing x.Petal_Length and x.Petal_Width to the plt.scatter() function.\n",
        "Call the plt.show() function to show your plot.\n",
        "How many clusters do you see?"
      ],
      "metadata": {
        "_uuid": "f943c72ec419bc46785b66b49e45185bf1d1ff54",
        "_cell_guid": "cb0be9a3-4012-44f4-a3ad-b9cd0479fd3c",
        "id": "OyceXkpK-f4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the plot\n",
        "plt.figure(figsize=(14,7))\n",
        " \n",
        "# Plot Sepal\n",
        "plt.subplot(1, 2, 1) # Creating subplots (1st subplot of 1 row, 2 columns)\n",
        "\n",
        "# Produce a scatter plot for the sepal length and width \n",
        "plt.scatter(x.Sepal_Length, x.Sepal_Width)\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('Width')\n",
        "\n",
        "plt.title('Sepal')\n",
        " \n",
        "plt.subplot(1, 2, 2)\n",
        "# Produce a scatter plot for the petal length and width \n",
        "plt.scatter(x.Petal_Length, x.Petal_Width)\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('Width')\n",
        "\n",
        "plt.title('Petal')"
      ],
      "metadata": {
        "_uuid": "e52f429ade6163fe028650a25062d1d1c3526deb",
        "_cell_guid": "7a5c9f9f-61c2-4246-9732-33b291bbee34",
        "id": "wnkbYTOX-f4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing with the size of data with Principal Component Analysis"
      ],
      "metadata": {
        "_uuid": "c2a1f3cb9f038da00ec804f5375adf43b5765e90",
        "_cell_guid": "631bf48d-286e-4634-87fc-3dbca24c8dca",
        "id": "EnEaaHaM-f4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sheer size of data in the modern age is not only a challenge for computer hardware but also a main bottleneck for the performance of many machine learning algorithms. The main goal of a PCA analysis is to identify patterns in data; PCA aims to detect the correlation between variables. If a strong correlation between variables exists, the attempt to reduce the dimensionality only makes sense. In a nutshell, this is what PCA is all about: Finding the directions of maximum variance in high-dimensional data and project it onto a smaller dimensional subspace while retaining most of the information.\n",
        "\n",
        "### PCA and Dimensionality Reduction\n",
        "\n",
        "Often, the desired goal is to reduce the dimensions of a $d$-dimensional dataset by projecting it onto a $(k)$-dimensional subspace (where $k<d$) in order to increase the computational efficiency while retaining most of the information. An important question is \"what is the size of $k$ that represents the data 'well'?\""
      ],
      "metadata": {
        "_uuid": "e6107747f27607a11864f94d6644f3052529a569",
        "_cell_guid": "0d3b868a-85e7-4235-9638-b3c86fbcf025",
        "id": "FhSJOhL9-f4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of Approach\n",
        "\n",
        "Instantiate (or create) the specific machine learning model you want to use\n",
        "Fit the model to the training data\n",
        "Use the model to make predictions\n",
        "\n",
        "* Standardise data\n",
        "* Instantiate [```PCA()```](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
        "* Fit ```PCA``` to the training data with the [```.fit```](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.fit function.)\n",
        "* Use ```PCA``` to [```transform```](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.transform) the training data"
      ],
      "metadata": {
        "_uuid": "64f6a1ae3c724f800251c605ab5a4da92d7168a3",
        "_cell_guid": "b3154df9-7541-4893-87af-003f3169f114",
        "id": "j5DjXiW4-f4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standardising your data\n",
        "\n",
        "##### Motivation\n",
        "\n",
        "Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization. For example, the majority of classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.\n",
        "\n",
        "Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators. \n",
        "There are various methods to normalize data. For this tutorial we are going to use the [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) from scikit-learn.\n",
        "\n",
        " ```python\n",
        " from sklearn.preprocessing import StandardScaler\n",
        "X_std = StandardScaler().fit_transform(X)\n",
        "```"
      ],
      "metadata": {
        "_uuid": "7b839e70cb10f723df3c56bc92f6e03699a9404a",
        "_cell_guid": "a49ec8df-e436-41bf-954d-1f7c5fb684e3",
        "id": "hUjJ0VA5-f4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variance of PCA features\n",
        "\n",
        "The iris dataset is 4-dimensional. But what is its **intrinsic dimension**? (**Intrinsic dimension** = number of features needed to approximate the dataset) Make a plot of the variances of the PCA features to find out. As before, samples is a 2D array, where each row represents a sample. You'll need to standardize the features first.\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "* Create an instance of StandardScaler called ```scaler```.\n",
        "* Create a PCA instance called ```pca```.\n",
        "* Use the ```.fit_transform()``` function of scaler and assign to ```X_norm``` to the iris samples.\n",
        "* Use the ```.fit``` function of pca to the scaled data ```X_norm```\n",
        "* Extract the number of components used using the ```.n_components_``` attribute of pca. Place this inside a range() function and store the result as features.\n",
        "* Use the plt.bar() function to plot the explained variances, with features on the x-axis and ```pca.explained_variance_``` on the y-axis."
      ],
      "metadata": {
        "_uuid": "e1311b917c0dc79b74a0d89d7ae5e74d6477aa64",
        "_cell_guid": "bfce9e70-8be1-4b1c-a5c4-53947f0a7cd3",
        "id": "HXkeng7y-f4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the necessary imports\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create scaler: scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Create a PCA instance: pca\n",
        "pca = PCA()\n",
        "\n",
        "# Fit_transform scaler to 'X'\n",
        "X_norm = scaler.fit_transform(x)"
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "leGlKD3s-f4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit pca to 'X'\n",
        "pca.fit(X_norm)\n",
        "\n",
        "# Plot the explained variances\n",
        "features = range(0, pca.n_components_)\n",
        "plt.bar(features, pca.explained_variance_)\n",
        "plt.xlabel('PCA feature')\n",
        "plt.ylabel('variance')\n",
        "plt.xticks(features)\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "e0164bedd67e52495fa8285fe3bcc4dca63bc73f",
        "_cell_guid": "a76946d2-c7b2-4294-a467-bd7c0ff954d0",
        "id": "11yKYuff-f4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at your plot, what do you think would be a reasonable choice for the \"intrinsic dimension\" of the the iris dataset? Recall that the intrinsic dimension is the number of PCA features with significant variance."
      ],
      "metadata": {
        "_uuid": "2a67f2a3675c6d36c9a8731c1b78302aaaf16724",
        "_cell_guid": "74485be9-a0b1-4a73-8963-6528cbb01b91",
        "id": "ZdIQIK6o-f4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dimension reduction of the iris dataset\n",
        "\n",
        "In a previous exercise, you found the \"intrinsic dimension\" to be some $k < 4$ of the iris dataset. Now use PCA for dimensionality reduction of the iris dataset, retaining only the 2 most important components.\n",
        "\n",
        "We have already been scaled above, and is available as ```X_norm```."
      ],
      "metadata": {
        "_uuid": "352debf7dd019206c450f0b8741d43dca65a716f",
        "_cell_guid": "23f65adc-1363-483a-867d-9645f48bb9ff",
        "id": "ZPk5xhLN-f4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instructions\n",
        "\n",
        "* Create a ```PCA``` instance called ```pca``` with ```n_components=2```.\n",
        "* Use the ```.fit()``` method of ```pca``` to fit it to the scaled iris data ```X_norm```.\n",
        "* Use the ```.transform()``` method of ```pca``` to transform the ```X_norm```. Assign the result to ```pca_features```."
      ],
      "metadata": {
        "_uuid": "0e89584a08920287ef1850fbe06a4b439221a854",
        "_cell_guid": "ae8fe9a5-beee-4d49-b1dd-43ead16b7a0b",
        "id": "DooJi9-s-f4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PCA model with 2 components: pca\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Fit the PCA instance to the scaled samples\n",
        "pca.fit(X_norm)\n",
        "\n",
        "# Transform the scaled samples: pca_features\n",
        "pca_features = pca.transform(X_norm)\n",
        "\n",
        "# Print the shape of pca_features\n",
        "print(pca_features.shape)"
      ],
      "metadata": {
        "_uuid": "0e07b334cbaa91ef64c1f7e8fff58241cc077019",
        "_cell_guid": "56ac3699-f540-4c68-8290-7f168adc6a77",
        "id": "PPrxzqGC-f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(pca_features[:, 0], pca_features[:, 1])"
      ],
      "metadata": {
        "id": "m6HRT-8z-f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Kmeans clustering?\n",
        "\n",
        "Kmeans clustering is an unsupervised learning technique to automatically group data into coherent clusters.\n",
        "\n",
        "Data: The model will take in training data\n",
        "Output: Cluster centroids and the labels for each data point. The labels tell us which clusters they belong to.\n",
        "\n",
        "### A summary of the algorithm\n",
        "\n",
        "Randomly intialize K cluster centroids.\n",
        "\n",
        "While the centroid positions are not the same,\n",
        "* For each data point, say x, find the cluster centroid closest to x.\n",
        "* Update cluster centers using data points assigned to them (Calculate the mean)\n"
      ],
      "metadata": {
        "_uuid": "2dc57795cfed3dc868dbda24b845e7e9fc51a138",
        "_cell_guid": "9cda4a82-7e2d-4fa8-8526-55a81bc6cfc3",
        "id": "7FhXE8Tt-f4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Kmeans model"
      ],
      "metadata": {
        "_uuid": "1d238f31230c0c58d22854814a54e0547f9c6eae",
        "_cell_guid": "e066dacc-fa13-4365-84be-176e6f3f1a08",
        "id": "qDCaGmMk-f4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the scatter plot of the previous exercise, you saw that the points seem to separate into 3 clusters. You'll now create a KMeans model to find 3 clusters, and fit it to the data points from the previous exercise. After the model has been fit, you'll obtain the cluster labels for some new points using the .predict() method.\n",
        "\n",
        "You are given the array points from the previous exercise, and also an array new_points.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Import KMeans from sklearn.cluster.\n",
        "* Using KMeans(), create a KMeans instance called model to find 3 clusters. To specify the number of clusters, use the n_clusters keyword argument.\n",
        "* Use the .fit() method of model to fit the model to the array of points points.\n",
        "* Use the .predict() method of model to predict the cluster labels of new_points, assigning the result to labels."
      ],
      "metadata": {
        "_uuid": "3edf8cfeac78bc37c8ecba220a0bd4d8940ffc10",
        "_cell_guid": "a55681d4-991a-4782-b6de-a42cf7d033fc",
        "id": "uk3SZi4W-f4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import KMeans\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Create a KMeans instance with 3 clusters: model\n",
        "model = KMeans(n_clusters=3)\n",
        "\n",
        "# Fit model to points\n",
        "model.fit(X_norm)\n",
        "\n",
        "# Determine the cluster labels of new_points: labels\n",
        "labels = model.labels_\n",
        "\n",
        "# Print cluster labels of new_points\n",
        "labels"
      ],
      "metadata": {
        "_uuid": "8b5121a1f8b7c3bd50c265399d43bea0a6bfb147",
        "_cell_guid": "774990df-f7e4-4360-94d5-892179023c6e",
        "id": "Nq2ER_OY-f4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect your clustering"
      ],
      "metadata": {
        "_uuid": "8a72809c716a5998f743dfd04fe394b1536e1996",
        "_cell_guid": "9d09e3e7-a797-44ab-9341-223b526004bf",
        "id": "4r1mYEhE-f4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Can check correspondence with e.g. iris species\n",
        "* â€¦ but what if there are no species to check against?\n",
        "* Measure quality of a clustering\n",
        "* Informs choice of how many clusters to look for"
      ],
      "metadata": {
        "_uuid": "2ae09927db1a64869dcf674e0d67ba09a524ab7f",
        "_cell_guid": "d77e26b1-9295-4502-bcab-d9acc5680872",
        "id": "CmX5xalA-f4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correspondence with iris species"
      ],
      "metadata": {
        "_uuid": "75d26ccd783258569ede0853ec9520f48cce8480",
        "_cell_guid": "caa84f12-3a50-42ed-b86f-ad35af1aebc5",
        "id": "OPDXv614-f4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "Use the ```pd.crosstab()``` function on ```df['labels']``` and ```df['varieties']``` to count the number of times each iris species coincides with each cluster label. Assign the result to ```ct```"
      ],
      "metadata": {
        "_uuid": "840c3bab6b48eefaf0fe262fa2411b2eb31e2b4d",
        "_cell_guid": "1f35543c-e45c-40a8-9b3b-561c3050eeb1",
        "id": "nocTcOrc-f4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a KMeans model with 3 clusters: model\n",
        "model = KMeans(n_clusters=3)\n",
        "\n",
        "# Use fit_predict to fit model and obtain cluster labels: labels\n",
        "labels = model.fit_predict(pca_features)\n",
        "\n",
        "# Create a DataFrame with labels and varieties as columns: df\n",
        "df = pd.DataFrame({'labels': labels, 'species': iris_species})\n",
        "\n",
        "# Create crosstab: ct\n",
        "ct = pd.crosstab(df['labels'], df['species'])\n",
        "\n",
        "# Display ct\n",
        "print(ct)"
      ],
      "metadata": {
        "_uuid": "3ce5563984e02801370d2a7f6c88d3f0218fb0f7",
        "_cell_guid": "92bd68f4-3fd4-4f01-8890-f7f6509dcd87",
        "id": "euUF0Lwb-f4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measuring Quality of Clustering"
      ],
      "metadata": {
        "_uuid": "81c1d60c443cd994cfd9303bf53fc5f26fceba79",
        "_cell_guid": "77a96043-cc34-4145-9ca0-3035d6938344",
        "id": "ZYLpWhg_-f4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Using only samples and their cluster labels\n",
        "* A good clustering has tight clusters\n",
        "* ... and samples in each cluster bunched together"
      ],
      "metadata": {
        "_uuid": "8c35fd03b8388534c643a1fbfade1939be3c5dec",
        "_cell_guid": "df4f8005-c299-42f3-85ec-3768cb663c37",
        "id": "5FZjRZwH-f4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Inertia measures clustering quality\n",
        "\n",
        "* Measures how spread out the clusters are (lower is better)\n",
        "* Distance from each sample to centroid of its cluster\n",
        "* Afer ```fit()```, available as attribute ```inertia_```\n",
        "* k-means attempts to minimize the inertia when choosing clusters\n",
        "\n",
        "```python\n",
        "from sklearn.cluster import KMeans\n",
        "model = KMeans(n_clusters=3)\n",
        "model.fit(samples)\n",
        "print(model.inertia_)\n",
        "78.9408414261\n",
        "```"
      ],
      "metadata": {
        "_uuid": "73d2777f5144c9419e30ff9b031397185a3537a1",
        "_cell_guid": "806edd5a-717e-4908-b599-2e243df9a250",
        "id": "tBUMvV1C-f4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "* For each of the given values of ```k```, perform the following steps:\n",
        "* Create a ```KMeans``` instance called model with k clusters.\n",
        "* Fit the model to the grain data samples.\n",
        "* Append the value of the ```inertia_``` attribute of model to the list ```inertias```.\n",
        "* The code to plot ```ks``` vs ```inertias``` has been written for you, so hit 'Shift + Enter' to see the plot!"
      ],
      "metadata": {
        "_uuid": "cc8f8fca93726957f8efe4bb85b40371f1b9e5b6",
        "_cell_guid": "a7e82e00-6d54-4868-9382-aa16f2b128b2",
        "id": "1JV_gOd7-f4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ks = range(1, 6)\n",
        "inertias = []\n",
        "\n",
        "for k in ks:\n",
        "    # Create a KMeans instance with k clusters: model\n",
        "    model = KMeans(n_clusters=k)\n",
        "    \n",
        "    # Fit model to samples\n",
        "    model.fit(pca_features)\n",
        "    \n",
        "    # Append the inertia to the list of inertias\n",
        "    inertias.append(model.inertia_)\n",
        "    \n",
        "# Plot ks vs inertias\n",
        "plt.plot(ks, inertias, '-o')\n",
        "plt.xlabel('number of clusters, k')\n",
        "plt.ylabel('inertia')\n",
        "plt.xticks(ks)\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "f91f5bac9ab346e414732a387df6a938c67f5456",
        "_cell_guid": "7dce3ac0-b388-4ec7-a9bb-c5384f080e60",
        "id": "NlkNokjD-f4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps"
      ],
      "metadata": {
        "_uuid": "f9657070eb8cba8bb0c546829336011a9bf6777c",
        "_cell_guid": "e420d455-01d2-4244-98d6-6838ee5495da",
        "id": "I0vUGrK4-f4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* PCA - Look at factor loadings\n",
        "* KMeans - Evaluation of cluster compactness by looking at Silhouette Score when we do not have access to labels to evaluate"
      ],
      "metadata": {
        "_uuid": "e5b6e8031d4c307c7329e9d0fb052682d25ae6d4",
        "_cell_guid": "02b89aa1-d26b-4971-8f8d-fcc4f7156073",
        "id": "bw4_Vm4J-f4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resources\n",
        "\n",
        "* https://www.datacamp.com/courses/unsupervised-learning-in-python"
      ],
      "metadata": {
        "_uuid": "13cf92935a430f5ba329db0c46111d87bd1b1d14",
        "_cell_guid": "8c3f8666-9240-4104-9a89-a1b4ed6172d2",
        "id": "epYO5xZD-f4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## THE END - WELL DONE!"
      ],
      "metadata": {
        "_uuid": "31d1989d37657636372e9b4b670cc6bc813e1c74",
        "_cell_guid": "f345d0eb-7e06-4704-b134-136e7c3b7892",
        "id": "PbcwA6d7-f4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "_uuid": "f2dad7ed9a01427f987d5af04b8676372c3df1cf",
        "_cell_guid": "a147d4f6-7c33-47eb-9e2b-e04f3257e612",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "TykVl4B5-f4M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}